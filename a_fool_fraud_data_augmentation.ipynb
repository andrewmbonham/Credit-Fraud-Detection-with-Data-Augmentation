{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Fool Fraud:\n",
    "## Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contents \n",
    "## Load and Preprocess Data \n",
    "## Data Augmentation\n",
    "### Split Data for Augmentation\n",
    "### GANs\n",
    "### SMOTE and ADASYN\n",
    "## Build and Evaluate Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from foolfraud import *\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE, ADASYN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"creditcard.csv\"\n",
    "data = load_and_describe(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = preprocess_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby(\"Class\").mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Data for Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraudulent, legitimate = split_by_class(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "test_size = 100\n",
    "train_fraud, test_fraud = train_test_split(\n",
    "    fraudulent, test_size=test_size, random_state=seed\n",
    ")\n",
    "test_size = int(test_size * (len(legitimate) / len(fraudulent)))\n",
    "train_legit, test_legit = train_test_split(\n",
    "    legitimate, test_size=test_size, random_state=seed\n",
    ")\n",
    "print(\n",
    "    f\"No. training fraudulent transactions: {len(train_fraud)}, testing: {len(test_fraud)}\"\n",
    ")\n",
    "train_data = pd.concat([train_fraud, train_legit]).sample(frac=1)\n",
    "print(f\"Original training data shape: {train_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.concat([test_fraud, test_legit]).sample(frac=1)\n",
    "X_test, y_test = test_data.iloc[:, :-1], test_data.iloc[:, -1]\n",
    "print(f\"Testing data shape: {test_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pct_test = 100 * (len(test_fraud) + len(test_legit)) / len(data)\n",
    "print(f\"Pct. data used for testing: {pct_test:.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GANs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_to_generate = len(train_legit) - len(train_fraud)\n",
    "print(f\"No. fraudulent transactions to generate: {n_to_generate}\\n\")\n",
    "\n",
    "gan_train_data = train_fraud.drop(\"Class\", axis=1)\n",
    "print(\"GAN training data head:\")\n",
    "gan_train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = (gan_train_data.shape[0], 1, gan_train_data.shape[1])\n",
    "gan_train_data = torch.tensor(gan_train_data.values).reshape(shape).float()\n",
    "gan_train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "epochs = 1000\n",
    "batch_size = 28\n",
    "sample_size = 64  # Number of random values to sample\n",
    "g_lr = 1.0e-3  # Generator's learning rate\n",
    "d_lr = 1.0e-4  # Discriminator's learning rate\n",
    "n_batches = int(gan_train_data.shape[0] / batch_size)\n",
    "print(f\"No. batches: {n_batches}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Real and fake labels\n",
    "real_targets = torch.ones(batch_size, 1)\n",
    "fake_targets = torch.zeros(batch_size, 1)\n",
    "\n",
    "# Generator and Discriminator networks\n",
    "generator = Generator(sample_size)\n",
    "discriminator = Discriminator()\n",
    "\n",
    "# Optimizers\n",
    "d_optimizer = torch.optim.Adam(discriminator.parameters(), lr=d_lr)\n",
    "g_optimizer = torch.optim.Adam(generator.parameters(), lr=g_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    d_losses = []\n",
    "    g_losses = []\n",
    "\n",
    "    for batch in range(n_batches):\n",
    "        # Discriminator Network Training\n",
    "        # Loss with fraud transaction inputs and real_targets as labels\n",
    "        start = int(batch * batch_size)\n",
    "        stop = start + batch_size\n",
    "        transactions = gan_train_data[start:stop]\n",
    "\n",
    "        discriminator.train()\n",
    "        d_loss = discriminator(transactions, real_targets)\n",
    "\n",
    "        # Generate transactions in eval mode\n",
    "        generator.eval()\n",
    "        with torch.no_grad():\n",
    "            generated_transactions = generator(batch_size)\n",
    "\n",
    "        # Loss with generated fraud transaction inputs and fake_targets as labels\n",
    "        d_loss += discriminator(generated_transactions, fake_targets)\n",
    "\n",
    "        # Optimizer updates the discriminator parameters\n",
    "        d_optimizer.zero_grad()\n",
    "        d_loss.backward()\n",
    "        d_optimizer.step()\n",
    "\n",
    "        # Generator Network Training\n",
    "        # Generate transactions in train mode\n",
    "        generator.train()\n",
    "        generated_transactions = generator(batch_size)\n",
    "\n",
    "        # Loss with generated fraud transaction inputs and real_targets as labels\n",
    "        g_loss = discriminator(generated_transactions, real_targets)\n",
    "\n",
    "        # Optimizer updates the generator parameters\n",
    "        g_optimizer.zero_grad()\n",
    "        g_loss.backward()\n",
    "        g_optimizer.step()\n",
    "\n",
    "        # Keep losses for logging\n",
    "        d_losses.append(d_loss.item())\n",
    "        g_losses.append(g_loss.item())\n",
    "\n",
    "    # Print average losses\n",
    "    if epoch % 10 == 0:\n",
    "        outstr = f\"epoch: {epoch} d_loss: {np.mean(d_losses):.3f} g_loss: {np.mean(g_losses):.3f}\"\n",
    "        print(outstr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate batches to generate\n",
    "full_batch_size = 100\n",
    "n_full_batches, last_batch_size = divmod(n_to_generate, full_batch_size)\n",
    "# generate and concatenate data from GAN\n",
    "gan_generated = [generate_transactions(generator) for _ in range(n_full_batches)]\n",
    "gan_generated += [generate_transactions(generator, last_batch_size)]\n",
    "gan_generated = pd.concat(gan_generated)\n",
    "gan_generated.columns = test_fraud.columns[:-1]\n",
    "print(f\"Generated data shape: {gan_generated.shape}\\n\")\n",
    "print(\"Generated data head:\")\n",
    "gan_generated.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build GAN training sets\n",
    "gan_generated.columns = test_fraud.columns[:-1]\n",
    "gan_generated[\"Class\"] = 1\n",
    "GAN_training_data = pd.concat([gan_generated, train_data]).sample(frac=1)\n",
    "X_train_GAN, y_train_GAN = GAN_training_data.iloc[:, :-1], GAN_training_data.iloc[:, -1]\n",
    "print(f\"GAN balance: {y_train_GAN.mean():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SMOTE and ADASYN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SMOTE and ADASYN training sets\n",
    "X_train, y_train = train_data.iloc[:, :-1], train_data.iloc[:, -1]\n",
    "X_train_SMOTE, y_train_SMOTE = SMOTE(random_state=seed).fit_resample(X_train, y_train)\n",
    "X_train_ADASYN, y_train_ADASYN = ADASYN(random_state=seed).fit_resample(\n",
    "    X_train, y_train\n",
    ")\n",
    "print(f\"SMOTE balance: {y_train_SMOTE.mean():.2f}\")\n",
    "print(f\"ADASYN balance: {y_train_ADASYN.mean():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build and Evaluate Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ext = \"smote\"\n",
    "smote_results = build_and_evaluate(\n",
    "    X_train_SMOTE, y_train_SMOTE, X_test, y_test, ext=ext\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ext = \"adasyn\"\n",
    "adasyn_results = build_and_evaluate(\n",
    "    X_train_ADASYN, y_train_ADASYN, X_test, y_test, ext=ext\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ext = \"gan\"\n",
    "gan_results = build_and_evaluate(X_train_GAN, y_train_GAN, X_test, y_test, ext=ext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
